{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec07579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b15267d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch, torch.nn as nn, torch.nn.functional as F, math, time, random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0); np.random.seed(0); random.seed(0)\n",
    "dim=4\n",
    "allowed_edges = torch.tensor([[0,1],[0,2],[0,3]], dtype=torch.long, device=device)\n",
    "def op_with_phase(i,j,dim,phi):\n",
    "    M = torch.zeros(dim,dim, dtype=torch.complex64, device=device)\n",
    "    M[i,j] = torch.exp(1j*phi)\n",
    "    M[j,i] = torch.exp(-1j*phi)\n",
    "    return M\n",
    "def step_unitary(edge_w, frac, phase):\n",
    "    phi = math.pi*phase\n",
    "    H = torch.zeros(dim,dim, dtype=torch.complex64, device=device)\n",
    "    for e in range(allowed_edges.shape[0]):\n",
    "        i,j = allowed_edges[e]\n",
    "        H = H + edge_w[e]*op_with_phase(int(i),int(j),dim,phi)\n",
    "    theta = math.pi*frac\n",
    "    A = (-1j*0.5*theta)*H\n",
    "    return torch.linalg.matrix_exp(A)\n",
    "def unitary_from_seq(edges_idx, fracs, phases):\n",
    "    U = torch.eye(dim, dtype=torch.complex64, device=device)\n",
    "    for e, f, p in zip(edges_idx, fracs, phases):\n",
    "        w = torch.zeros(allowed_edges.shape[0], device=device); w[int(e)] = 1.0\n",
    "        U = step_unitary(w, f, p) @ U\n",
    "    return U\n",
    "def phase_align(U,V):\n",
    "    X = V.conj().transpose(-2,-1) @ U\n",
    "    tr = X.diagonal(dim1=-2,dim2=-1).sum(-1)\n",
    "    ang = torch.atan2(tr.imag, tr.real).view(-1,1,1)\n",
    "    return U * torch.exp(-1j*ang)\n",
    "\n",
    "def frob_loss(U,V):\n",
    "    d = U.shape[-1]\n",
    "    U2 = phase_align(U,V)\n",
    "    diff = U2 - V\n",
    "    sf = (diff.real**2 + diff.imag**2).sum(dim=(-2,-1))\n",
    "    return (sf/(d*d)).mean()\n",
    "\n",
    "def infidelity(U,V):\n",
    "    d = U.shape[-1]\n",
    "    X = V.conj().transpose(-2,-1) @ U\n",
    "    tr = X.diagonal(dim1=-2,dim2=-1).sum(-1).abs()\n",
    "    return (1.0 - tr/d).mean()\n",
    "def physics_loss(U_pred, U_true, fracs, w_frob=1.0, w_fid=1.0, w_len=0.1):\n",
    "    Lf = frob_loss(U_pred, U_true)\n",
    "    Li = infidelity(U_pred, U_true)\n",
    "    L1 = fracs.abs().sum()/fracs.numel()\n",
    "    return w_frob*Lf + w_fid*Li + w_len*L1, (Lf,Li,L1)\n",
    "def rand_seq(L, phase_set=(0.5,1.5), fmax=2.0):\n",
    "    edges = torch.randint(0,3,(L,), device=device)\n",
    "    fracs = fmax*torch.rand(L, device=device)\n",
    "    phases = torch.tensor(random.choices(phase_set,k=L), device=device)\n",
    "    return edges, fracs, phases\n",
    "\n",
    "def make_batch(B,L, fmax=2.0):\n",
    "    Us=[]; seqs=[]\n",
    "    for _ in range(B):\n",
    "        e,f,p = rand_seq(L, fmax=fmax)\n",
    "        U = unitary_from_seq(e,f,p)\n",
    "        Us.append(U.unsqueeze(0)); seqs.append((e,f,p))\n",
    "    U = torch.cat(Us,0)\n",
    "    return U, seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c62fcd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_targets(seqs, L):\n",
    "    edges_true = torch.stack([s[0][:L] for s in seqs],0).long().to(device)\n",
    "    fracs_true = torch.stack([s[1][:L] for s in seqs],0).float().to(device)\n",
    "    phases_true = torch.stack([s[2][:L] for s in seqs],0).float().to(device)\n",
    "    return edges_true, fracs_true, phases_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "744c0e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Triton detected; running without torch.compile\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "TRITON_OK = importlib.util.find_spec(\"triton\") is not None\n",
    "\n",
    "class InvNet(nn.Module):\n",
    "    def __init__(self, d=4, Lmax=5):\n",
    "        super().__init__()\n",
    "        inp = 2*d*d\n",
    "        h=1024\n",
    "        self.net = nn.Sequential(nn.Linear(inp,h), nn.GELU(), nn.Linear(h,h), nn.GELU(), nn.Linear(h,h), nn.GELU())\n",
    "        self.head_edges = nn.Linear(h, Lmax*3)\n",
    "        self.head_fracs = nn.Linear(h, Lmax)\n",
    "        self.head_phases = nn.Linear(h, Lmax)\n",
    "        self.Lmax=Lmax\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        logits = self.head_edges(z).view(-1,self.Lmax,3)\n",
    "        fracs = 2.0*torch.sigmoid(self.head_fracs(z))\n",
    "        phases = 2.0*torch.sigmoid(self.head_phases(z))\n",
    "        return logits, fracs, phases\n",
    "\n",
    "model = InvNet(d=dim, Lmax=5).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4, fused=(device=='cuda'))\n",
    "\n",
    "if TRITON_OK:\n",
    "    try:\n",
    "        model = torch.compile(model)\n",
    "        print(\"torch.compile enabled\")\n",
    "    except Exception:\n",
    "        print(\"torch.compile not enabled\")\n",
    "else:\n",
    "    print(\"No Triton detected; running without torch.compile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9776cbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_unitary_batched(w, frac, phase):\n",
    "    B = w.shape[0]\n",
    "    ephi = torch.exp(1j*torch.pi*phase)\n",
    "    H = torch.zeros(B, dim, dim, dtype=torch.complex64, device=device)\n",
    "    for e in range(allowed_edges.shape[0]):\n",
    "        i, j = allowed_edges[e]\n",
    "        H[:, i, j] += w[:, e] * ephi\n",
    "        H[:, j, i] += w[:, e] * ephi.conj()\n",
    "    theta = torch.pi * frac\n",
    "    A = (-1j*0.5) * theta.view(-1,1,1) * H\n",
    "    return torch.linalg.matrix_exp(A)\n",
    "\n",
    "def pred_unitary_from_outputs(logits, fracs, phases, L, tau=1.0, hard=True):\n",
    "    B = logits.shape[0]\n",
    "    U = torch.eye(dim, dtype=torch.complex64, device=device).unsqueeze(0).repeat(B,1,1)\n",
    "    for t in range(L):\n",
    "        w = F.gumbel_softmax(logits[:, t, :], tau=tau, hard=hard)\n",
    "        f = fracs[:, t]\n",
    "        p = phases[:, t]\n",
    "        U_step = step_unitary_batched(w, f, p)\n",
    "        U = U_step @ U\n",
    "    return U\n",
    "\n",
    "\n",
    "def train_epoch(curr_L, steps=200, B=64, tau=1.0, w_frob=1.0, w_fid=1.0, w_len=0.1, use_sup=True, lam_edge=2.0, lam_frac=1.0, lam_phase=1.0, lam_ent=0.01, clip=1.0, fmax=2.0):\n",
    "    model.train()\n",
    "    mloss=0.0\n",
    "    for _ in range(steps):\n",
    "        U_true, seqs = make_batch(B, curr_L)\n",
    "        x = encode_unitary(U_true).to(device)\n",
    "        logits, fracs, phases = model(x)\n",
    "        U_pred = pred_unitary_from_outputs(logits, fracs, phases, curr_L, tau=tau, hard=True)\n",
    "        L,(Lf,Li,L1) = physics_loss(U_pred, U_true, fracs[:,:curr_L], w_frob, w_fid, w_len)\n",
    "        probs = logits[:,:curr_L,:].softmax(-1)\n",
    "        ent = -(probs.clamp_min(1e-8)*probs.clamp_min(1e-8).log()).sum(-1).mean()\n",
    "        L = L + lam_ent*ent\n",
    "        if use_sup:\n",
    "            e_t, f_t, p_t = pack_targets(seqs, curr_L)\n",
    "            ce = F.cross_entropy(logits[:,:curr_L,:].reshape(-1,3), e_t.reshape(-1))\n",
    "            mse_f = F.mse_loss(fracs[:,:curr_L], f_t)\n",
    "            mse_p = F.mse_loss(phases[:,:curr_L], p_t)\n",
    "            L = L + lam_edge*ce + lam_frac*mse_f + lam_phase*mse_p\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        L.backward()\n",
    "        if clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        opt.step()\n",
    "        mloss += L.item()\n",
    "    return mloss/steps\n",
    "\n",
    "def eval_epoch(curr_L, B=64, tau=0.5, w_frob=1.0, w_fid=1.0, w_len=0.1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        U_true,_ = make_batch(B, curr_L)\n",
    "        x = encode_unitary(U_true)\n",
    "        logits, fracs, phases = model(x)\n",
    "        U_pred = pred_unitary_from_outputs(logits, fracs, phases, curr_L, tau=tau, hard=True)\n",
    "        L,(Lf,Li,L1) = physics_loss(U_pred, U_true, fracs[:,:curr_L], w_frob, w_fid, w_len)\n",
    "    return L.item(), Lf.item(), Li.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9665854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=1 epoch=0 train=0.7331 val_total=0.0459 val_frob=0.0085 val_inf=0.0169\n",
      "L=1 epoch=1 train=0.2631 val_total=0.0378 val_frob=0.0058 val_inf=0.0115\n",
      "L=1 epoch=2 train=0.2351 val_total=0.0302 val_frob=0.0037 val_inf=0.0074\n",
      "L=1 epoch=3 train=0.2293 val_total=0.0318 val_frob=0.0039 val_inf=0.0078\n",
      "L=1 epoch=4 train=0.1934 val_total=0.0292 val_frob=0.0032 val_inf=0.0063\n",
      "L=1 epoch=5 train=0.1942 val_total=0.0347 val_frob=0.0049 val_inf=0.0097\n",
      "L=2 epoch=0 train=3.5463 val_total=0.4640 val_frob=0.1492 val_inf=0.2984\n",
      "L=2 epoch=1 train=2.0221 val_total=0.3641 val_frob=0.1157 val_inf=0.2313\n",
      "L=2 epoch=2 train=1.4064 val_total=0.2678 val_frob=0.0837 val_inf=0.1674\n",
      "L=2 epoch=3 train=1.2207 val_total=0.2844 val_frob=0.0891 val_inf=0.1781\n",
      "L=2 epoch=4 train=1.1140 val_total=0.2327 val_frob=0.0718 val_inf=0.1437\n",
      "L=2 epoch=5 train=1.0521 val_total=0.2182 val_frob=0.0670 val_inf=0.1339\n",
      "L=3 epoch=0 train=3.5955 val_total=0.6472 val_frob=0.2104 val_inf=0.4207\n",
      "L=3 epoch=1 train=2.5884 val_total=0.5548 val_frob=0.1798 val_inf=0.3596\n",
      "L=3 epoch=2 train=2.5041 val_total=0.5504 val_frob=0.1784 val_inf=0.3568\n",
      "L=3 epoch=3 train=2.4547 val_total=0.5222 val_frob=0.1689 val_inf=0.3379\n",
      "L=3 epoch=4 train=2.4193 val_total=0.5017 val_frob=0.1620 val_inf=0.3240\n",
      "L=3 epoch=5 train=2.3944 val_total=0.5626 val_frob=0.1822 val_inf=0.3643\n",
      "L=4 epoch=0 train=3.2054 val_total=0.7509 val_frob=0.2454 val_inf=0.4909\n",
      "L=4 epoch=1 train=3.0854 val_total=0.7242 val_frob=0.2364 val_inf=0.4729\n",
      "L=4 epoch=2 train=3.0655 val_total=0.7456 val_frob=0.2436 val_inf=0.4873\n",
      "L=4 epoch=3 train=3.0392 val_total=0.7052 val_frob=0.2302 val_inf=0.4605\n",
      "L=4 epoch=4 train=3.0215 val_total=0.7149 val_frob=0.2333 val_inf=0.4666\n",
      "L=4 epoch=5 train=3.0124 val_total=0.6739 val_frob=0.2198 val_inf=0.4396\n",
      "L=5 epoch=0 train=3.4971 val_total=0.8757 val_frob=0.2871 val_inf=0.5742\n",
      "L=5 epoch=1 train=3.4314 val_total=0.8626 val_frob=0.2826 val_inf=0.5652\n",
      "L=5 epoch=2 train=3.4164 val_total=0.8957 val_frob=0.2935 val_inf=0.5870\n",
      "L=5 epoch=3 train=3.3960 val_total=0.8443 val_frob=0.2766 val_inf=0.5533\n",
      "L=5 epoch=4 train=3.3803 val_total=0.8744 val_frob=0.2864 val_inf=0.5729\n",
      "L=5 epoch=5 train=3.3764 val_total=0.8527 val_frob=0.2793 val_inf=0.5586\n"
     ]
    }
   ],
   "source": [
    "cfg = dict(w_frob=1.0, w_fid=1.0, w_len=0.02, epochs_per_L=6, total_L=5, steps_per_epoch=120, B=256, tau_start=0.8, tau_end=0.1, use_sup=True, lam_edge=2.0, lam_frac=1.0, lam_phase=1.0, lam_ent=0.02)\n",
    "hist = []\n",
    "for L in range(1, cfg['total_L']+1):\n",
    "    for e in range(cfg['epochs_per_L']):\n",
    "        t = 0 if cfg['epochs_per_L']==1 else e/(cfg['epochs_per_L']-1)\n",
    "        tau = cfg['tau_start'] + (cfg['tau_end']-cfg['tau_start'])*t\n",
    "        fmax = 0.8 + 1.2*min(1.0, (L-1)/4.0)\n",
    "        tr = train_epoch(L, steps=cfg['steps_per_epoch'], B=cfg['B'], tau=tau, w_frob=cfg['w_frob'], w_fid=cfg['w_fid'], w_len=cfg['w_len'], use_sup=cfg['use_sup'], lam_edge=cfg['lam_edge'], lam_frac=cfg['lam_frac'], lam_phase=cfg['lam_phase'], lam_ent=cfg['lam_ent'], clip=1.0, fmax=fmax)\n",
    "        vl, vf, vi = eval_epoch(L, B=cfg['B'], tau=0.05, w_frob=cfg['w_frob'], w_fid=cfg['w_fid'], w_len=cfg['w_len'])\n",
    "        hist.append((L, e, tr, vl, vf, vi))\n",
    "        print(f\"L={L} epoch={e} train={tr:.4f} val_total={vl:.4f} val_frob={vf:.4f} val_inf={vi:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
